{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2 — Task 2: Multiple Linear Regression (All Features → median_house_value)\n",
        "\n",
        "Author: LUV-KUSHWAHA\n",
        "\n",
        "This notebook completes Task 2 of the assignment: build a multiple linear regression model using all available input features to predict `median_house_value`.\n",
        "\n",
        "It follows the ML pipeline steps with clear, line-by-line comments in code cells so you can copy-paste directly into your assignment notebook/script.\n",
        "\n",
        "Notes:\n",
        "- The notebook first attempts to load a local CSV (common Kaggle variant with `ocean_proximity`). If not found, it falls back to scikit-learn's California housing dataset (which does NOT include `ocean_proximity`).\n",
        "- We handle missing values (median imputation for `total_bedrooms`), encode categorical features (`ocean_proximity`) if present, scale numeric features, train LinearRegression, and report coefficients and evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports and setup\n",
        "\n",
        "Import required libraries and set plotting style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import numpy as np                                  # numerical ops\n",
        "import pandas as pd                                 # DataFrame handling\n",
        "import matplotlib.pyplot as plt                     # plotting\n",
        "import seaborn as sns                               # nicer plots\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Optional imports for encoding / imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "sns.set(style='whitegrid', context='notebook')      # plotting style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Data retrieval and collection\n",
        "\n",
        "Try to load a local CSV (Kaggle-style California housing with `ocean_proximity`). If not available, fall back to scikit-learn dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attempt to read a local CSV first (common filenames used by many tutorials)\n",
        "csv_candidates = ['housing.csv', 'california_housing.csv', 'housing.csv']  # try common names\n",
        "df = None\n",
        "for fname in csv_candidates:\n",
        "    try:\n",
        "        df = pd.read_csv(fname)                        # try to load CSV\n",
        "        print(f\"Loaded data from local file: {fname}\")\n",
        "        break\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if df is None:\n",
        "    # Fallback: use scikit-learn's California housing dataset\n",
        "    from sklearn.datasets import fetch_california_housing\n",
        "    housing = fetch_california_housing(as_frame=True)\n",
        "    df = housing.data.copy()\n",
        "    df['median_house_value'] = housing.target\n",
        "    # rename feature to match assignment naming\n",
        "    if 'HouseAge' in df.columns:\n",
        "        df = df.rename(columns={'HouseAge': 'housing_median_age'})\n",
        "    print('Loaded scikit-learn California housing dataset (no ocean_proximity column).')\n",
        "\n",
        "# Quick top-level inspect\n",
        "print('\\nDataset shape (rows, cols):', df.shape)\n",
        "print('\\nColumns:')\n",
        "print(list(df.columns))\n",
        "\n",
        "# Show first rows (visual inspection)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Data cleaning\n",
        "\n",
        "Check missing values and data types, then handle missing values (we will impute `total_bedrooms` using the median)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values per column\n",
        "missing = df.isnull().sum()\n",
        "print('Missing counts per column:\\n')\n",
        "print(missing)\n",
        "\n",
        "# Report fraction missing for total_bedrooms if present\n",
        "if 'total_bedrooms' in df.columns:\n",
        "    total_rows = df.shape[0]\n",
        "    n_missing = missing['total_bedrooms']\n",
        "    frac = n_missing / total_rows\n",
        "    print(f\"\\ntotal_bedrooms missing: {n_missing} rows ({frac:.2%} of dataset)\")\n",
        "\n",
        "# Data types\n",
        "print('\\nData types:')\n",
        "print(df.dtypes)\n",
        "\n",
        "# Imputation strategy: median for total_bedrooms (robust to outliers)\n",
        "if 'total_bedrooms' in df.columns and df['total_bedrooms'].isnull().any():\n",
        "    imp_med = SimpleImputer(strategy='median')        # median imputer\n",
        "    df[['total_bedrooms']] = imp_med.fit_transform(df[['total_bedrooms']])\n",
        "    print('\\nApplied median imputation to total_bedrooms.')\n",
        "\n",
        "# Verify no missing values remain (for numeric columns used later)\n",
        "print('\\nMissing counts after imputation:')\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observation: we used median imputation for `total_bedrooms` because it was the only column with many missing entries and median is robust to outliers.\n",
        "If you prefer, multiple imputation (MICE) or model-based imputation are alternatives for final reporting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Feature design\n",
        "\n",
        "Prepare the feature matrix X and target y. Encode categorical features (`ocean_proximity`) using one-hot encoding if present. Scale numeric features with StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify target and drop it from features\n",
        "target_col = 'median_house_value'\n",
        "if target_col not in df.columns:\n",
        "    raise ValueError(f\"Target column '{target_col}' not found in dataset\")\n",
        "\n",
        "X = df.drop(columns=[target_col]).copy()            # features DataFrame\n",
        "y = df[target_col].copy()                            # target Series\n",
        "\n",
        "# Handle categorical column 'ocean_proximity' if present\n",
        "categorical_cols = [c for c in X.columns if X[c].dtype == 'object' or X[c].dtype.name == 'category']\n",
        "print('Categorical columns detected:', categorical_cols)\n",
        "\n",
        "if len(categorical_cols) > 0:\n",
        "    # Use pandas one-hot encoding for simplicity and interpretability\n",
        "    X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)  # drop_first avoids collinearity with intercept\n",
        "    print('\\nApplied one-hot encoding to categorical columns. New shape:', X.shape)\n",
        "\n",
        "# Now scale numeric features using StandardScaler (recommended when features have different scales)\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()   # numeric feature list\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols)\n",
        "\n",
        "# Final feature matrix\n",
        "X_final = X_scaled.copy()\n",
        "print('\\nFinal features shape (after encoding & scaling):', X_final.shape)\n",
        "X_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Why scaling? LinearRegression does not require scaling for correctness, but scaling helps interpret coefficient magnitudes when predictors have very different units and is useful for diagnostics and comparability. We scaled here to keep features on comparable scales and to make coefficient comparisons meaningful in standardized units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Algorithm selection & loss\n",
        "\n",
        "We use Ordinary Least Squares Linear Regression and evaluate with Mean Squared Error (MSE) and R². This choice is consistent with Task 1 and gives interpretable coefficients for each (standardized) feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6) Model learning: split data and fit\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.20, random_state=42)\n",
        "\n",
        "model = LinearRegression()                           # ordinary least squares model\n",
        "model.fit(X_train, y_train)                          # fit model on training data\n",
        "\n",
        "print('Model trained.')\n",
        "print(f'Intercept: {model.intercept_:.4f}')\n",
        "\n",
        "# Map coefficients to feature names (note: features are standardized so coefficients refer to 1-std changes)\n",
        "coef_series = pd.Series(model.coef_, index=X_final.columns).sort_values(ascending=False)\n",
        "print('\\nTop 10 positive coefficients (feature : coef):')\n",
        "print(coef_series.head(10))\n",
        "print('\\nTop 10 negative coefficients (feature : coef):')\n",
        "print(coef_series.tail(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpretation note: Because we scaled numeric features (zero mean, unit variance), each coefficient represents the expected change in median_house_value for a one-standard-deviation increase in that feature, holding others constant. For one-hot encoded binary features (e.g., ocean_proximity_X), coefficients represent the expected change when that category is present vs the reference category, on the same (standardized) scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Model evaluation\n",
        "\n",
        "Evaluate on the test set (MSE, RMSE, R²) and present diagnostic plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictions on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Test MSE: {mse:.4f}')\n",
        "print(f'Test RMSE: {rmse:.4f}')\n",
        "print(f'Test R²: {r2:.4f}')\n",
        "\n",
        "# Residuals\n",
        "residuals = y_test - y_pred\n",
        "print('\\nResiduals summary:')\n",
        "print(pd.Series(residuals).describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot 1: Predicted vs Actual\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual median_house_value')\n",
        "plt.ylabel('Predicted median_house_value')\n",
        "plt.title('Predicted vs Actual — Multiple Linear Regression (Test set)')\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Residuals vs Fitted\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_pred, residuals, alpha=0.6)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted values (predictions)')\n",
        "plt.ylabel('Residuals (actual - predicted)')\n",
        "plt.title('Residuals vs Fitted')\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Residuals distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(residuals, kde=True, bins=40, color='purple')\n",
        "plt.xlabel('Residual (actual - predicted)')\n",
        "plt.title('Residuals distribution (Test set)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model coefficients (detailed)\n",
        "\n",
        "List all coefficients with feature names so they can be interpreted in the assignment. Because numeric features were standardized, coefficients correspond to a 1‑standard‑deviation change in the predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a clear table of feature, coefficient, and absolute importance\n",
        "coef_table = pd.DataFrame({\n",
        "    'feature': X_final.columns,\n",
        "    'coefficient': model.coef_\n",
        "})\n",
        "coef_table['abs_coef'] = coef_table['coefficient'].abs()\n",
        "coef_table = coef_table.sort_values(by='abs_coef', ascending=False)\n",
        "coef_table.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Show top 20 most important features by absolute coefficient\n",
        "coef_table.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison to Task 1 and conclusion\n",
        "\n",
        "Summarize improvement over single-feature model and final recommendations to include in your assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Summary:')\n",
        "print('- Using multiple features typically improves predictive performance relative to the single-feature model because more relevant information is provided to the learner.')\n",
        "print('- Report the metrics above (MSE, RMSE, R²) and discuss whether the R² and RMSE indicate good predictive performance for your use-case.')\n",
        "\n",
        "print('\\nRecommendations:')\n",
        "print('1) If residual diagnostics show heteroscedasticity or non-linearity, try target-transformations (log) or polynomial features.')\n",
        "print('2) Consider regularized regression (Ridge, Lasso) if overfitting or coefficient instability is a concern.')\n",
        "print('3) For inference, provide confidence intervals or run bootstrap to quantify uncertainty; for production, evaluate on a held-out validation set.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables (what to paste into your assignment)\n",
        "\n",
        "Include:\n",
        "- The code cells above (with comments) in your notebook.\n",
        "- The imputation strategy and rationale (we used median for total_bedrooms).\n",
        "- The final evaluation metrics (MSE, RMSE, R²) and coefficient table.\n",
        "- Diagnostic plots and an interpretation of whether linear regression assumptions hold.\n",
        "\n",
        "If you want, I can also produce a notebook variant that:\n",
        "- Uses Ridge/Lasso and compares cross-validated RMSE, or\n",
        "- Outputs a ready-to-submit PDF or .py script version of this notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}